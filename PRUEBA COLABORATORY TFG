//CODIGO PARA PROBAR QUE NOS FUNCIONA LA APLICACION

//IMPORTAMOS TODOS LOS MODULOS NECESARIOS DE PYTHON
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import math

//CREAMOS FUENTE DE DATOS ENTRENAMIENTO
SAMPLES = 1000

x_values = np.random.uniform(low=0, high=2*math.pi, size=SAMPLES)
np.random.shuffle(x_values)
y_values = np.sin(x_values)

plt.plot(x_values, y_values, 'r.')
plt.show()  

//AGREGAMOS RUIDO
y_values += 0.1 * np.random.randn(*y_values.shape)

plt.plot(x_values, y_values, 'b.')
plt.show()

//DIVIDIMOS LA FUENTE DE DATOS
TRAIN_SPLIT =  int(0.6 * SAMPLES)
TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)

x_train, x_validate, x_test = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])
y_train, y_validate, y_test = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])

assert (x_train.size + x_validate.size + x_test.size) ==  SAMPLES

plt.plot(x_train, y_train, 'b.', label="Train")
plt.plot(x_validate, y_validate, 'y.', label="Validate")
plt.plot(x_test, y_test, 'r.', label="Test")
plt.legend()
plt.show()

//COMPILAMOS EL MODELO
from tensorflow.keras import layers

model = tf.keras.Sequential()
model.add(layers.Dense(16, activation='relu', input_shape=(1,)))
model.add(layers.Dense(16, activation='relu'))
model.add(layers.Dense(16, activation='relu'))
model.add(layers.Dense(1))
model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])
model.summary()

//HACEMOS UN AJUSTE PARA EL ENTRENAMIENTO DEL MODELO
history = model.fit(x_train, y_train, 
                    epochs=600, batch_size=16,
                    validation_data=(x_validate, y_validate))
                    
//PROBAMOS EL MODELO
loss = model.evaluate(x_test, y_test)
predictions = model.predict(x_test)

plt.clf()
plt.title('Comparison of predictions and actual values')
plt.plot(x_test, y_test, 'b.', label='Actual')
plt.plot(x_test, predictions, 'r.', label='Predicted')
plt.legend()
plt.show()

//EXPORTAMOS EL MODELO ENTRENADO
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
open("sine_model.tflite", "wb").write(tflite_model)

//PASAMOS DE TFLITE A CODIGO C
!apt-get -qq install xxd
!xxd -i sine_model.tflite > sine_model.h

//LUEGO CON EL SIGUIENTE CODIGO DE ARDUINO Y EL ARCHIVO QUE HEMOS DESCARGADO COMPROBAMOS LA APLICACION
// PUEDES UTILIZAR BLUETOOTH O WiFi
#define BLUETOOTH "ESP32BT"
#if defined(BLUETOOTH)
  #include "esp32dumbdisplay.h"
  DumbDisplay dumbdisplay(new DDBluetoothSerialIO(BLUETOOTH));
#elif defined(WIFI_SSID)
  #include "wifidumbdisplay.h"
  DumbDisplay dumbdisplay(new DDWiFiServerIO(WIFI_SSID, WIFI_PASSWORD));
#else
  #include "dumbdisplay.h"
  DumbDisplay dumbdisplay(new DDInputOutput());
#endif


#include <TensorFlowLite_ESP32.h>
#include "tensorflow/lite/micro/all_ops_resolver.h"
#include "tensorflow/lite/micro/micro_error_reporter.h"
#include "tensorflow/lite/micro/micro_interpreter.h"
#include "tensorflow/lite/schema/schema_generated.h"


#include "sine_model.h"


class DDTFLErrorReporter : public tflite::ErrorReporter {
public:
  virtual int Report(const char* format, va_list args) {
    int len = strlen(format);
    char buffer[max(32, 2 * len)]; 
    sprintf(buffer, format, args);
    dumbdisplay.writeComment(buffer);
    return 0;
  }
};


DDTFLErrorReporter error_reporter_impl;
tflite::ErrorReporter* error_reporter = &error_reporter_impl;



const tflite::Model* model = ::tflite::GetModel(sine_model_tflite);

// This pulls in all the operation implementations we need
tflite::AllOpsResolver resolver;

const int tensor_arena_size = 2 * 1024;
uint8_t tensor_arena[tensor_arena_size];  


tflite::MicroInterpreter interpreter(model, resolver, tensor_arena,
                                     tensor_arena_size, error_reporter);


TfLiteTensor* input;



PlotterDDLayer* plotterLayer;
GraphicalDDLayer* graphicalLayer;


const float start_in = -1.4;
const float max_in = 7.6;

const int width = 640;
const int height = 360;
const float xScaleFactor = width / (max_in - start_in);
const float yScaleFactor = height / 2;
const int xOffset = -start_in * xScaleFactor;
const int yOffset = yScaleFactor;



void setup() {
  plotterLayer = dumbdisplay.createPlotterLayer(width, height);

  graphicalLayer = dumbdisplay.createGraphicalLayer(width, height);
  graphicalLayer->backgroundColor("ivory");
  graphicalLayer->drawLine(0, yOffset, width, yOffset, "blue");
  graphicalLayer->drawLine(xOffset, 0, xOffset, height, "blue");

  dumbdisplay.configAutoPin(DD_AP_VERT);

  if (model->version() != TFLITE_SCHEMA_VERSION) {
    error_reporter->Report("Model provided is schema version %d not equal to supported version %d.\n",
    model->version(), TFLITE_SCHEMA_VERSION);
  }

  interpreter.AllocateTensors();

  input = interpreter.input(0);
}


float in = start_in;
int color = 0; // 0: "red"; 1: "green"

void loop() {
  delay(250);

  input->data.f[0] = in;

  TfLiteStatus invoke_status = interpreter.Invoke();
  if (invoke_status != kTfLiteOk) {
    error_reporter->Report("Invoke failed\n");
  }

  TfLiteTensor* output = interpreter.output(0);

  float out = output->data.f[0];

  plotterLayer->set("x", in, "y", out);

  int x = xOffset + in * xScaleFactor;
  int y = yOffset - out * yScaleFactor; 
  graphicalLayer->fillCircle(x, y, 2, color == 0 ? "red" : "green");

  float inc = (float) random(10) / 1000.0;
  in += 0.04 + inc;

  if (in > max_in) {
    in = start_in + (inc / 3.0);
    color = (color + 1) % 2;
  }
}
